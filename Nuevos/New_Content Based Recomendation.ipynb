{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "baf75b55-b4b4-4e8e-b00d-df150e0217be",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#!pip install -U sentence-transformers\n",
    "#!pip install -U pandas\n",
    "#!pip install -U numpy\n",
    "#pip install -U sklearn\n",
    "#!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f957a732-9f4d-4ca7-9a01-49bc558c3000",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#importamos librerias \"necesarias\"\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "85e66460-237e-49a2-b09c-f57d974d007f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('D:/Pedro Esparza/Archivos/BDs/Recomendation/Nuevos/New_Animes.csv')\n",
    "data2 = pd.read_csv('D:/Pedro Esparza/Archivos/BDs/Recomendation/Vistos/Animes.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cuantos nuevos hay\n",
    "valNuevos = data1[\"ID\"].count() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparamos los datos\n",
    "data = pd.concat([data1, data2], ignore_index=True)\n",
    "data.reset_index(drop = True, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "20dfae57-72b1-4315-bff5-807a86432d0d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Nos basamos en la sinopsis por palabra\n",
    "X = np.array(data.SinopsisPalabra)\n",
    "#Nos basamos en los generos\n",
    "Y = np.array(data.Genre)\n",
    "#Nos basamos en la sinopsis por oracion\n",
    "Z = np.array(data.Sinopsis)\n",
    "text_data = X\n",
    "text_data1 = Y\n",
    "text_data2 = Z\n",
    "model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
    "embeddings = model.encode(text_data, show_progress_bar=False)\n",
    "embeddings1 = model.encode(text_data1, show_progress_bar=False)\n",
    "embeddings2 = model.encode(text_data2, show_progress_bar=False)\n",
    "\n",
    "X = np.array(embeddings)\n",
    "Y = np.array(embeddings1)\n",
    "Z = np.array(embeddings2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8fd2004a-52d7-4897-bcbc-253646c8dd05",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#metodo que da la recomenacion de los 3 mas cercanos en el cosine\n",
    "def give_recommendations(index):\n",
    "  used_cos_sim_data = pd.DataFrame(cosine_similarity(X))\n",
    "  if(index >= valNuevos):\n",
    "    used_cos_sim_data.pop(index)\n",
    "  else:\n",
    "    for new in range(0,valNuevos,1):\n",
    "      used_cos_sim_data.pop(new)\n",
    "  index_recomm =used_cos_sim_data.loc[index].sort_values(ascending=False).index.tolist()[1:4] #recomendaciones\n",
    "  movies_recomm =  data['Title'].loc[index_recomm].values\n",
    "  example = data['Title'].loc[index]\n",
    "  result = {'Anime':example, '1st recomm':movies_recomm[0],'2nd recomm':movies_recomm[1],'3rd recomm':movies_recomm[2]}\n",
    "  return result\n",
    "\n",
    "def give_recommendations1(index):\n",
    "  used_cos_sim_data = pd.DataFrame(cosine_similarity(Y))\n",
    "  if(index >= valNuevos):\n",
    "    used_cos_sim_data.pop(index)\n",
    "  else:\n",
    "    for new in range(0,valNuevos,1):\n",
    "      used_cos_sim_data.pop(new)\n",
    "  index_recomm =used_cos_sim_data.loc[index].sort_values(ascending=False).index.tolist()[1:4] #recomendaciones\n",
    "  movies_recomm =  data['Title'].loc[index_recomm].values\n",
    "  example = data['Title'].loc[index]\n",
    "  result = {'Anime':example, '1st recomm':movies_recomm[0],'2nd recomm':movies_recomm[1],'3rd recomm':movies_recomm[2]}\n",
    "  return result\n",
    "\n",
    "def give_recommendations2(index):\n",
    "  used_cos_sim_data = pd.DataFrame(cosine_similarity(Z))\n",
    "  if(index >= valNuevos):\n",
    "    used_cos_sim_data.pop(index)\n",
    "  else:\n",
    "    for new in range(0,valNuevos,1):\n",
    "      used_cos_sim_data.pop(new)\n",
    "  index_recomm =used_cos_sim_data.loc[index].sort_values(ascending=False).index.tolist()[1:4] #recomendaciones\n",
    "  movies_recomm =  data['Title'].loc[index_recomm].values\n",
    "  example = data['Title'].loc[index]\n",
    "  result = {'Anime':example, '1st recomm':movies_recomm[0],'2nd recomm':movies_recomm[1],'3rd recomm':movies_recomm[2]}\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb1f7af9-797f-4a0a-abb1-41b5791785a3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "x = data.count()\n",
    "\n",
    "UpLimit = x['ID']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ac43d12-cd04-4f86-b11e-ca8d8d525dab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Corremos la funcion por cada uno\n",
    "arreglo=[]\n",
    "arreglo1=[]\n",
    "arreglo2=[]\n",
    "for i in range(0,UpLimit,1):\n",
    "  resultado = give_recommendations(i)\n",
    "  resultado1 = give_recommendations1(i)\n",
    "  resultado2 = give_recommendations2(i)\n",
    "  arreglo.append(resultado)\n",
    "  arreglo1.append(resultado1)\n",
    "  arreglo2.append(resultado2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b1bffb3b-53a3-4760-a0db-12dcb73ea8aa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Tranformamos a dataframe\n",
    "dfLect1 = pd.DataFrame(arreglo)\n",
    "dfLect3 = pd.DataFrame(arreglo1)\n",
    "dfLect2 = pd.DataFrame(arreglo2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#guardamos\n",
    "dfLect1.to_csv('D:/Pedro Esparza/Archivos/BDs/Recomendation/Nuevos/Recom_Palabra.csv', index = False, sep=\",\" )\n",
    "dfLect3.to_csv('D:/Pedro Esparza/Archivos/BDs/Recomendation/Nuevos/Recom_Genero.csv', index = False, sep=\",\" )\n",
    "dfLect2.to_csv('D:/Pedro Esparza/Archivos/BDs/Recomendation/Nuevos/Recom_Oracion.csv', index = False, sep=\",\" )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segunda parte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tomamos solo los animes que no se han visto\n",
    "dfNuevos = pd.DataFrame()  \n",
    "dfNuevos[\"Anime\"] =data1[\"Title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agrupamos las veces que se recomendo cierto anime en algna de las 3 posiciones por separado por palabra\n",
    "dfResults1 = pd.DataFrame()  \n",
    "dfResults1 = dfLect1[\"1st recomm\"].value_counts()\n",
    "dfResults1 = dfResults1.to_frame()\n",
    "dfResults1 = dfResults1.reset_index()\n",
    "dfResults1.columns  = [\"Anime\", \"1st\"]\n",
    "\n",
    "dfResults2 = pd.DataFrame()  \n",
    "dfResults2 = dfLect1[\"2nd recomm\"].value_counts()\n",
    "dfResults2 = dfResults2.to_frame()\n",
    "dfResults2 = dfResults2.reset_index()\n",
    "dfResults2.columns  = [\"Anime\", \"2nd\"]\n",
    "\n",
    "dfResults3 = pd.DataFrame()  \n",
    "dfResults3 = dfLect1[\"3rd recomm\"].value_counts()\n",
    "dfResults3 = dfResults3.to_frame()\n",
    "dfResults3 = dfResults3.reset_index()\n",
    "dfResults3.columns  = [\"Anime\", \"3rd\"]\n",
    "\n",
    "#agrupamos las veces que se recomendo cierto anime en algna de las 3 posiciones por separado por oracion\n",
    "dfResults4 = pd.DataFrame()  \n",
    "dfResults4 = dfLect2[\"1st recomm\"].value_counts()\n",
    "dfResults4 = dfResults4.to_frame()\n",
    "dfResults4 = dfResults4.reset_index()\n",
    "dfResults4.columns  = [\"Anime\", \"1st\"]\n",
    "\n",
    "dfResults5 = pd.DataFrame()  \n",
    "dfResults5 = dfLect2[\"2nd recomm\"].value_counts()\n",
    "dfResults5 = dfResults5.to_frame()\n",
    "dfResults5 = dfResults5.reset_index()\n",
    "dfResults5.columns  = [\"Anime\", \"2nd\"]\n",
    "\n",
    "dfResults6 = pd.DataFrame()  \n",
    "dfResults6 = dfLect2[\"3rd recomm\"].value_counts()\n",
    "dfResults6 = dfResults6.to_frame()\n",
    "dfResults6 = dfResults6.reset_index()\n",
    "dfResults6.columns  = [\"Anime\", \"3rd\"]\n",
    "\n",
    "#agrupamos las veces que se recomendo cierto anime en algna de las 3 posiciones por separado por genero\n",
    "dfResults7 = pd.DataFrame()  \n",
    "dfResults7 = dfLect3[\"1st recomm\"].value_counts()\n",
    "dfResults7 = dfResults7.to_frame()\n",
    "dfResults7 = dfResults7.reset_index()\n",
    "dfResults7.columns  = [\"Anime\", \"1st\"]\n",
    "\n",
    "dfResults8 = pd.DataFrame()  \n",
    "dfResults8 = dfLect3[\"2nd recomm\"].value_counts()\n",
    "dfResults8 = dfResults8.to_frame()\n",
    "dfResults8 = dfResults8.reset_index()\n",
    "dfResults8.columns  = [\"Anime\", \"2nd\"]\n",
    "\n",
    "dfResults9 = pd.DataFrame()  \n",
    "dfResults9 = dfLect3[\"3rd recomm\"].value_counts()\n",
    "dfResults9 = dfResults9.to_frame()\n",
    "dfResults9 = dfResults9.reset_index()\n",
    "dfResults9.columns  = [\"Anime\", \"3rd\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#left join de cada uno para saber cuantas veces se recomendo cada anime que no se ha visto en la posicion 1 2 o 3 por palabra\n",
    "inner_join1 = pd.merge(dfNuevos, \n",
    "                      dfResults1, \n",
    "                      on ='Anime', \n",
    "                      how ='left')\n",
    "inner_join2 = pd.merge(inner_join1, \n",
    "                      dfResults2, \n",
    "                      on ='Anime', \n",
    "                      how ='left')\n",
    "inner_join3 = pd.merge(inner_join2, \n",
    "                      dfResults3, \n",
    "                      on ='Anime', \n",
    "                      how ='left')\n",
    "\n",
    "#left join de cada uno para saber cuantas veces se recomendo cada anime que no se ha visto en la posicion 1 2 o 3 por oracion\n",
    "inner_join4 = pd.merge(dfNuevos, \n",
    "                      dfResults4, \n",
    "                      on ='Anime', \n",
    "                      how ='left')\n",
    "inner_join5 = pd.merge(inner_join1, \n",
    "                      dfResults5, \n",
    "                      on ='Anime', \n",
    "                      how ='left')\n",
    "inner_join6 = pd.merge(inner_join2, \n",
    "                      dfResults6, \n",
    "                      on ='Anime', \n",
    "                      how ='left')\n",
    "\n",
    "#left join de cada uno para saber cuantas veces se recomendo cada anime que no se ha visto en la posicion 1 2 o 3 por genero\n",
    "inner_join7 = pd.merge(dfNuevos, \n",
    "                      dfResults7, \n",
    "                      on ='Anime', \n",
    "                      how ='left')\n",
    "inner_join8 = pd.merge(inner_join1, \n",
    "                      dfResults8, \n",
    "                      on ='Anime', \n",
    "                      how ='left')\n",
    "inner_join9 = pd.merge(inner_join2, \n",
    "                      dfResults9, \n",
    "                      on ='Anime', \n",
    "                      how ='left')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculamos el total por renglon por palabra\n",
    "dfResultados1 = pd.DataFrame()  \n",
    "dfResultados1 = inner_join3\n",
    "dfResultados1 = dfResultados1.fillna(0)\n",
    "dfResultados1[\"Total\"] = dfResultados1[\"1st\"]+dfResultados1[\"2nd\"]+dfResultados1[\"3rd\"]\n",
    "dfResultados1 = dfResultados1.sort_values(by=['Total'], ascending=False)\n",
    "\n",
    "#Calculamos el total por renglon por oracion\n",
    "dfResultados2 = pd.DataFrame()  \n",
    "dfResultados2 = inner_join6\n",
    "dfResultados2 = dfResultados2.fillna(0)\n",
    "dfResultados2[\"Total\"] = dfResultados2[\"1st\"]+dfResultados2[\"2nd\"]+dfResultados2[\"3rd\"]\n",
    "dfResultados12 = dfResultados2.sort_values(by=['Total'], ascending=False)\n",
    "\n",
    "#Calculamos el total por renglon por genero\n",
    "dfResultados3 = pd.DataFrame()  \n",
    "dfResultados3 = inner_join9\n",
    "dfResultados3 = dfResultados3.fillna(0)\n",
    "dfResultados3[\"Total\"] = dfResultados3[\"1st\"]+dfResultados3[\"2nd\"]+dfResultados3[\"3rd\"]\n",
    "dfResultados3 = dfResultados3.sort_values(by=['Total'], ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#juntamos los tres resultados\n",
    "dataRecomendadaTMP = pd.concat([dfResultados1, dfResultados2], ignore_index=True)\n",
    "dataRecomendadaTMP.reset_index(drop = True, inplace = True)\n",
    "dataRecomendada = pd.concat([dataRecomendadaTMP, dfResultados3], ignore_index=True)\n",
    "dataRecomendada.reset_index(drop = True, inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agregamos la columnas de total\n",
    "dataAgrupada = dataRecomendada.groupby(['Anime'])['Total'].sum()\n",
    "dataAgrupada = dataAgrupada.to_frame()\n",
    "dataAgrupada = dataAgrupada.reset_index()\n",
    "dataAgrupada.columns  = [\"Anime\",\"Total\"]\n",
    "dataAgrupada = dataAgrupada.sort_values(by=['Total'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#juntamos todos los dataframes\n",
    "dfResults1.columns  = [\"Anime\", \"Recoms\"]\n",
    "dfResults2.columns  = [\"Anime\", \"Recoms\"]\n",
    "dfResults3.columns  = [\"Anime\", \"Recoms\"]\n",
    "dfResults4.columns  = [\"Anime\", \"Recoms\"]\n",
    "dfResults5.columns  = [\"Anime\", \"Recoms\"]\n",
    "dfResults6.columns  = [\"Anime\", \"Recoms\"]\n",
    "dfResults7.columns  = [\"Anime\", \"Recoms\"]\n",
    "dfResults8.columns  = [\"Anime\", \"Recoms\"]\n",
    "dfResults9.columns  = [\"Anime\", \"Recoms\"]\n",
    "resultadoFinal = pd.concat([dfResults1, dfResults2, dfResults3, dfResults4, dfResults5, dfResults6, dfResults7, dfResults8, dfResults9], ignore_index=True)\n",
    "resultadoFinal = resultadoFinal.reset_index()\n",
    "\n",
    "\n",
    "#sumamos las apariciones\n",
    "resultadoFinal = resultadoFinal.groupby(['Anime'])['Recoms'].sum()\n",
    "resultadoFinal = resultadoFinal.to_frame()\n",
    "resultadoFinal = resultadoFinal.reset_index()\n",
    "resultadoFinal.columns  = [\"Anime\",\"Total\"]\n",
    "resultadoFinal = resultadoFinal.sort_values(by=['Total'], ascending=False)\n",
    "resultadoFinal = resultadoFinal.reset_index()\n",
    "resultadoFinal=resultadoFinal.drop(['index'], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos la columna con el contador que es el index\n",
    "resultadoFinal[\"Lugar\"] = resultadoFinal.index+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#buscamos el cuartil 3 \n",
    "xyz = resultadoFinal.count()\n",
    "\n",
    "UpLimit2 = xyz['Anime']\n",
    "UpLimit2 = round(UpLimit2*.75)\n",
    "UpLimit2\n",
    "dfMinimo = resultadoFinal[resultadoFinal[\"Lugar\"] == UpLimit2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sacamos el valor del cuartil 3 para usarlo como filtro\n",
    "val = dfMinimo[\"Total\"]\n",
    "x = val.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtramos los que tengan menos de 20 recomendaciones\n",
    "dataFiltrada = dataAgrupada[dataAgrupada[\"Total\"] >= x[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#guardamoos el resultado\n",
    "dataAgrupada.to_csv('D:/Pedro Esparza/Archivos/BDs/Recomendation/Nuevos/NuevasRecomendaciones/Count_based/Recom_todas.csv', index = False, sep=\",\" )\n",
    "#guardamoos los mayores a 5(75% de los animes aparecen en 5 o mas recomendaciones)\n",
    "dataFiltrada.to_csv('D:/Pedro Esparza/Archivos/BDs/Recomendation/Nuevos/NuevasRecomendaciones/Count_based/Recomendaciones.csv', index = False, sep=\",\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empezamos con scored based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\p_mau\\AppData\\Local\\Temp\\ipykernel_103444\\3759684187.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfScores[\"1st recomm\"] =dfScores[\"Title\"]\n",
      "C:\\Users\\p_mau\\AppData\\Local\\Temp\\ipykernel_103444\\3759684187.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfScores[\"2nd recomm\"] =dfScores[\"Title\"]\n",
      "C:\\Users\\p_mau\\AppData\\Local\\Temp\\ipykernel_103444\\3759684187.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfScores[\"3rd recomm\"] =dfScores[\"Title\"]\n"
     ]
    }
   ],
   "source": [
    "#segmentamos 3 bases de scores para el join\n",
    "dfScores = data2[[\"Title\",\"Score\"]]\n",
    "dfScores[\"1st recomm\"] =dfScores[\"Title\"]\n",
    "dfScores[\"2nd recomm\"] =dfScores[\"Title\"]\n",
    "dfScores[\"3rd recomm\"] =dfScores[\"Title\"]\n",
    "dfScores1 = dfScores[[\"1st recomm\",\"Score\"]]\n",
    "dfScores2 = dfScores[[\"2nd recomm\",\"Score\"]]\n",
    "dfScores3 = dfScores[[\"3rd recomm\",\"Score\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#con dfLect1\n",
    "score_join1 = pd.merge(dfLect1, \n",
    "                      dfScores1, \n",
    "                      on ='1st recomm', \n",
    "                      how ='left')\n",
    "score_join1 = pd.merge(score_join1, \n",
    "                      dfScores2, \n",
    "                      on ='2nd recomm', \n",
    "                      how ='left')\n",
    "score_join1 = pd.merge(score_join1, \n",
    "                      dfScores3, \n",
    "                      on ='3rd recomm', \n",
    "                      how ='left')\n",
    "\n",
    "#con dfLect2\n",
    "score_join2 = pd.merge(dfLect2, \n",
    "                      dfScores1, \n",
    "                      on ='1st recomm', \n",
    "                      how ='left')\n",
    "score_join2 = pd.merge(score_join2, \n",
    "                      dfScores2, \n",
    "                      on ='2nd recomm', \n",
    "                      how ='left')\n",
    "score_join2 = pd.merge(score_join2, \n",
    "                      dfScores3, \n",
    "                      on ='3rd recomm', \n",
    "                      how ='left')\n",
    "\n",
    "\n",
    "#con dfLect3\n",
    "score_join3 = pd.merge(dfLect3, \n",
    "                      dfScores1, \n",
    "                      on ='1st recomm', \n",
    "                      how ='left')\n",
    "score_join3 = pd.merge(score_join3, \n",
    "                      dfScores2, \n",
    "                      on ='2nd recomm', \n",
    "                      how ='left')\n",
    "score_join3 = pd.merge(score_join3, \n",
    "                      dfScores3, \n",
    "                      on ='3rd recomm', \n",
    "                      how ='left')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unimos los 3 tipos de recomendacion\n",
    "score_join1 = score_join1[[\"Anime\",\"Score_x\",\"Score_y\",\"Score\"]]\n",
    "score_join2 = score_join2[[\"Anime\",\"Score_x\",\"Score_y\",\"Score\"]]\n",
    "score_join3 = score_join3[[\"Anime\",\"Score_x\",\"Score_y\",\"Score\"]]\n",
    "\n",
    "dataScores = pd.concat([score_join1, score_join2,score_join3], ignore_index=True)\n",
    "dataScores.reset_index(drop = True, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Limpiamos nulos\n",
    "dataScores = dataScores.fillna(0)\n",
    "#Sacamos el total\n",
    "dataScores[\"Total\"] = dataScores[\"Score\"] + dataScores[\"Score_x\"] + dataScores[\"Score_y\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrupamos las 3\n",
    "dataScores = dataScores[[\"Anime\",\"Total\"]]\n",
    "dataScoresFinal = dataScores.groupby(['Anime'])['Total'].mean()\n",
    "\n",
    "dataScoresFinal = dataScoresFinal.to_frame()\n",
    "dataScoresFinal = dataScoresFinal.reset_index()\n",
    "dataScoresFinal.columns  = [\"Anime\",\"Total\"]\n",
    "\n",
    "#Promedio de las recomendaciones\n",
    "valPromedio = round(dataScoresFinal[\"Total\"].mean(),0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtro de solo nuevo\n",
    "dfNuevos_Score = pd.merge(dfNuevos, \n",
    "                      dataScoresFinal, \n",
    "                      on ='Anime', \n",
    "                      how ='left')\n",
    "\n",
    "dfNuevos_Score_Recom = dfNuevos_Score[dfNuevos_Score[\"Total\"] >= valPromedio]\n",
    "dfNuevos_Score_Recom = dfNuevos_Score_Recom.sort_values(by=['Total'],ascending=False)\n",
    "dfNuevos_Score_Recom[\"Total\"] = round(dfNuevos_Score_Recom[\"Total\"],1)\n",
    "\n",
    "dfNuevos_Score = dfNuevos_Score.sort_values(by=['Total'],ascending=False)\n",
    "dfNuevos_Score[\"Total\"] = round(dfNuevos_Score[\"Total\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "#guardamoos el resultado\n",
    "dfNuevos_Score.to_csv('D:/Pedro Esparza/Archivos/BDs/Recomendation/Nuevos/NuevasRecomendaciones/Score_based/Recom_todas.csv', index = False, sep=\",\" )\n",
    "#guardamoos los mayores al valor promedio\n",
    "dfNuevos_Score_Recom.to_csv('D:/Pedro Esparza/Archivos/BDs/Recomendation/Nuevos/NuevasRecomendaciones/Score_based/Recomendaciones.csv', index = False, sep=\",\" )\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Content Based Recomendation",
   "notebookOrigID": 2831764750789204,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3.10.10 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "fc72549f0a1f9445c45dde033697fce6a3cfe2434aa63e5158dde8da80c6e94b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
